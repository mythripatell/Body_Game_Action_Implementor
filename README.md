# Body_Game_Action_Implementor

A real-time computer visionâ€“based system that detects **hand gestures** and translates them into actionable commands for interaction â€” enabling basic gesture-controlled game play and user input. This project leverages **OpenCV** and **MediaPipe** to track body landmarks and interpret motion logic in live video feeds.

---

## ğŸ¯ Objective

To create an intuitive, contactless system for recognizing hand gestures and mapping them to functional actions, suitable for games or interactive simulations. This project offers an early exploration into **gesture-based interfaces** using real-time computer vision.

---

## ğŸ§  Tech Stack

- **Language**: Python  
- **Libraries**:
  - OpenCV
  - MediaPipe (for pose and hand tracking)
  - NumPy
- **Platform**: PC / Webcam interface

---

## ğŸ› ï¸ Features

- ğŸ“· Real-time webcam capture and hand tracking  
- âœ‹ Static and dynamic hand gesture detection  
- ğŸ® Action mapping (e.g., forward, jump, crouch, shoot) from hand poses  
- ğŸ” Pose-based calibration to adapt to userâ€™s position  

---

## ğŸ§ª Sample Actions (Mapping Examples)

| Gesture             | Mapped Action       |
|---------------------|---------------------|
| Two Fingers Raised  | Move Forward        |
| Fist                | Shoot               |
| Palm Open           | Idle / Neutral      |
| Thumbs Up           | Confirm Action      |

---

## ğŸ“ˆ Visual Outputs

You can view the output and test runs by uploading screenshots to:




---

## ğŸ“ Folder Structure

```text
body-action-implementor/
â”œâ”€â”€ images/                   # Screenshots of gesture actions
â”‚   â”œâ”€â”€ gesture_forward.png
â”‚   â””â”€â”€ gesture_shoot.png
â”œâ”€â”€ data/                     # Sample gesture data (if applicable)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ gesture_tracking.py   # Main detection script
â”‚   â””â”€â”€ action_mapper.py      # Mapping gestures to actions
â”œâ”€â”€ requirements.txt          # Required libraries
â””â”€â”€ README.md                 # Project documentation


